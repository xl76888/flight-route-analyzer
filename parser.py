# D:\flight_tool\parser.py
import pandas as pd
import re
import os
import numpy as np
from typing import List, Dict, Any, Tuple, Optional

def parse_route_text(text):
    """è§£æèˆªçº¿æ–‡æœ¬ï¼Œæå–èµ·ç‚¹å’Œç»ˆç‚¹ä¿¡æ¯"""
    if pd.isna(text) or not str(text).strip():
        return []
    
    # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²èˆªçº¿æ–‡æœ¬
    parts = re.split(r'\s*[-â€”>\u2192]\s*', str(text).strip())
    results = []
    
    for p in parts:
        # æå–IATAä»£ç 
        m = re.search(r'([A-Z]{3})', p)
        iata = m.group(1) if m else None
        # æ¸…ç†åŸå¸‚åç§°
        clean_name = re.sub(r'\([A-Z]{3}\)', '', p).strip()
        results.append({"name": clean_name, "iata": iata})
    
    # ç”Ÿæˆèˆªæ®µ
    segments = []
    for i in range(len(results) - 1):
        segments.append((results[i], results[i + 1]))
    
    return segments

def detect_table_structure(df: pd.DataFrame) -> Dict[str, Any]:
    """æ™ºèƒ½æ£€æµ‹è¡¨æ ¼ç»“æ„å’Œåˆ—æ˜ å°„"""
    structure = {
        'airline_col': None,
        'route_cols': [],
        'origin_col': None,
        'destination_col': None,
        'aircraft_col': None,
        'flight_number_col': None,
        'frequency_col': None,
        'reg_col': None,
        'age_col': None,
        'flight_time_cols': [],
        'flight_distance_cols': [],
        'special_col': None,
        'data_start_row': 0,
        'has_merged_cells': False
    }
    
    # åˆ—åå…³é”®è¯æ˜ å°„
    column_keywords = {
        'airline': ['èˆªå¸', 'èˆªç©ºå…¬å¸', 'å…¬å¸', 'airline', 'carrier'],
        'route': ['èˆªçº¿', 'è·¯çº¿', 'route', 'å‡ºå£èˆªçº¿', 'è¿›å£èˆªçº¿'],
        'origin': ['èµ·ç‚¹', 'å‡ºå‘åœ°', 'å§‹å‘åœ°', 'origin', 'departure', 'èµ·é£'],
        'destination': ['ç»ˆç‚¹', 'ç›®çš„åœ°', 'åˆ°è¾¾åœ°', 'destination', 'arrival', 'é™è½'],
        'aircraft': ['æœºå‹', 'é£æœºå‹å·', 'aircraft', 'plane', 'æœºç§'],
        'flight_number': ['èˆªç­å·', 'ç­æ¬¡', 'flight', 'number'],
        'frequency': ['é¢‘ç‡', 'ç­æœŸ', 'frequency', 'è¿è¥'],
        'reg': ['æ³¨å†Œå·', 'reg', 'æœºå·', 'å°¾å·'],
        'age': ['æœºé¾„', 'age', 'å¹´é¾„'],
        'flight_time': ['é£è¡Œæ—¶é•¿', 'é£è¡Œæ—¶é—´', 'time', 'æ—¶é•¿'],
        'flight_distance': ['é£è¡Œè·ç¦»', 'è·ç¦»', 'distance', 'é‡Œç¨‹'],
        'special': ['ç‰¹æ®Š', 'å¤‡æ³¨', 'è¯´æ˜', 'special', 'note']
    }
    
    # æ£€æµ‹åˆ—æ˜ å°„
    for col in df.columns:
        col_str = str(col).lower().strip()
        
        for key, keywords in column_keywords.items():
            if any(keyword in col_str for keyword in keywords):
                if key == 'route':
                    structure['route_cols'].append(col)
                elif key == 'flight_time':
                    structure['flight_time_cols'].append(col)
                elif key == 'flight_distance':
                    structure['flight_distance_cols'].append(col)
                else:
                    structure[f'{key}_col'] = col
                break
    
    # æ£€æµ‹æ•°æ®å¼€å§‹è¡Œï¼ˆè·³è¿‡æ ‡é¢˜å’Œç©ºè¡Œï¼‰
    for i, row in df.iterrows():
        if not row.isna().all() and any(str(val).strip() for val in row if pd.notna(val)):
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ•°æ®è¡Œè€Œä¸æ˜¯æ ‡é¢˜è¡Œ
            non_empty_values = [str(val).strip() for val in row if pd.notna(val) and str(val).strip()]
            if len(non_empty_values) >= 2:  # è‡³å°‘æœ‰2ä¸ªéç©ºå€¼æ‰è®¤ä¸ºæ˜¯æ•°æ®è¡Œ
                structure['data_start_row'] = i
                break
    
    # æ£€æµ‹æ˜¯å¦æœ‰åˆå¹¶å•å…ƒæ ¼ï¼ˆé€šè¿‡æ£€æŸ¥é‡å¤å€¼æ¨¡å¼ï¼‰
    if len(df) > 1:
        for col in df.columns:
            consecutive_same = 0
            max_consecutive = 0
            prev_val = None
            
            for val in df[col]:
                if pd.notna(val) and val == prev_val:
                    consecutive_same += 1
                    max_consecutive = max(max_consecutive, consecutive_same)
                else:
                    consecutive_same = 0
                prev_val = val
            
            if max_consecutive > 2:  # è¿ç»­3ä¸ªä»¥ä¸Šç›¸åŒå€¼å¯èƒ½æ˜¯åˆå¹¶å•å…ƒæ ¼
                structure['has_merged_cells'] = True
                break
    
    return structure

def clean_and_normalize_data(df: pd.DataFrame, structure: Dict[str, Any]) -> pd.DataFrame:
    """æ¸…ç†å’Œæ ‡å‡†åŒ–æ•°æ®"""
    # ä»æ£€æµ‹åˆ°çš„æ•°æ®å¼€å§‹è¡Œå¼€å§‹å¤„ç†
    if structure['data_start_row'] > 0:
        df = df.iloc[structure['data_start_row']:].reset_index(drop=True)
    
    # åˆ é™¤å®Œå…¨ç©ºç™½çš„è¡Œ
    df = df.dropna(how='all').reset_index(drop=True)
    
    # å¤„ç†åˆå¹¶å•å…ƒæ ¼ï¼ˆå‘ä¸‹å¡«å……ï¼‰
    if structure['has_merged_cells']:
        # å¯¹å…³é”®åˆ—è¿›è¡Œå‰å‘å¡«å……
        key_cols = [structure['airline_col'], structure['aircraft_col'], structure['reg_col']]
        for col in key_cols:
            if col and col in df.columns:
                df[col] = df[col].fillna(method='ffill')
    
    # æ¸…ç†æ–‡æœ¬æ•°æ®
    for col in df.columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).str.strip()
            df[col] = df[col].replace(['nan', 'NaN', '', 'None'], np.nan)
    
    return df

def categorize_city_for_direction(city_name: str) -> str:
    """åˆ¤æ–­åŸå¸‚æ˜¯å›½å†…è¿˜æ˜¯å›½å¤–ï¼ˆç”¨äºæ–¹å‘åˆ¤æ–­ï¼‰"""
    # ä¸­å›½ä¸»è¦åŸå¸‚åˆ—è¡¨ï¼ˆåŒ…æ‹¬æ¸¯æ¾³å°ï¼‰
    chinese_cities = {
        # ç›´è¾–å¸‚
        'åŒ—äº¬', 'ä¸Šæµ·', 'å¤©æ´¥', 'é‡åº†',
        # çœä¼šåŸå¸‚
        'å¹¿å·', 'æ·±åœ³', 'æ­å·', 'å—äº¬', 'æ­¦æ±‰', 'æˆéƒ½', 'è¥¿å®‰', 'éƒ‘å·', 'æµå—', 'æ²ˆé˜³',
        'é•¿æ˜¥', 'å“ˆå°”æ»¨', 'çŸ³å®¶åº„', 'å¤ªåŸ', 'å‘¼å’Œæµ©ç‰¹', 'å…°å·', 'è¥¿å®', 'é“¶å·', 'ä¹Œé²æœ¨é½',
        'åˆè‚¥', 'ç¦å·', 'å—æ˜Œ', 'é•¿æ²™', 'æµ·å£', 'å—å®', 'è´µé˜³', 'æ˜†æ˜', 'æ‹‰è¨',
        # å…¶ä»–é‡è¦åŸå¸‚
        'è‹å·', 'æ— é”¡', 'å¸¸å·', 'å—é€š', 'å¾å·', 'æ‰¬å·', 'é•‡æ±Ÿ', 'æ³°å·', 'ç›åŸ', 'æ·®å®‰', 'å®¿è¿', 'è¿äº‘æ¸¯',
        'å®æ³¢', 'æ¸©å·', 'å˜‰å…´', 'æ¹–å·', 'ç»å…´', 'é‡‘å', 'è¡¢å·', 'èˆŸå±±', 'å°å·', 'ä¸½æ°´',
        'é’å²›', 'çƒŸå°', 'æ½åŠ', 'ä¸´æ²‚', 'æ·„åš', 'æµå®', 'æ³°å®‰', 'å¨æµ·', 'æ—¥ç…§', 'æ»¨å·',
        'ä¸œè¥', 'èŠåŸ', 'å¾·å·', 'èæ³½', 'æ£åº„', 'è±èŠœ',
        'å¤§è¿', 'éå±±', 'æŠšé¡º', 'æœ¬æºª', 'ä¸¹ä¸œ', 'é”¦å·', 'è¥å£', 'é˜œæ–°', 'è¾½é˜³', 'ç›˜é”¦',
        'é“å²­', 'æœé˜³', 'è‘«èŠ¦å²›',
        'é•¿æ˜¥', 'å‰æ—', 'å››å¹³', 'è¾½æº', 'é€šåŒ–', 'ç™½å±±', 'æ¾åŸ', 'ç™½åŸ', 'å»¶è¾¹',
        'å“ˆå°”æ»¨', 'é½é½å“ˆå°”', 'é¸¡è¥¿', 'é¹¤å²—', 'åŒé¸­å±±', 'å¤§åº†', 'ä¼Šæ˜¥', 'ä½³æœ¨æ–¯', 'ä¸ƒå°æ²³',
        'ç‰¡ä¸¹æ±Ÿ', 'é»‘æ²³', 'ç»¥åŒ–', 'å¤§å…´å®‰å²­',
        'å¦é—¨', 'æ³‰å·', 'æ¼³å·', 'è†ç”°', 'ä¸‰æ˜', 'é¾™å²©', 'å—å¹³', 'å®å¾·',
        'å—æ˜Œ', 'æ™¯å¾·é•‡', 'èä¹¡', 'ä¹æ±Ÿ', 'æ–°ä½™', 'é¹°æ½­', 'èµ£å·', 'å‰å®‰', 'å®œæ˜¥', 'æŠšå·', 'ä¸Šé¥¶',
        'ç æµ·', 'æ±•å¤´', 'ä½›å±±', 'éŸ¶å…³', 'æ¹›æ±Ÿ', 'è‚‡åº†', 'æ±Ÿé—¨', 'èŒ‚å', 'æƒ å·', 'æ¢…å·',
        'æ±•å°¾', 'æ²³æº', 'é˜³æ±Ÿ', 'æ¸…è¿œ', 'ä¸œè', 'ä¸­å±±', 'æ½®å·', 'æ­é˜³', 'äº‘æµ®',
        'æŸ³å·', 'æ¡‚æ—', 'æ¢§å·', 'åŒ—æµ·', 'é˜²åŸæ¸¯', 'é’¦å·', 'è´µæ¸¯', 'ç‰æ—', 'ç™¾è‰²', 'è´ºå·',
        'æ²³æ± ', 'æ¥å®¾', 'å´‡å·¦',
        'ä¸‰äºš', 'ä¸‰æ²™', 'å„‹å·',
        'éµä¹‰', 'å…­ç›˜æ°´', 'å®‰é¡º', 'æ¯•èŠ‚', 'é“œä»', 'é»”è¥¿å—', 'é»”ä¸œå—', 'é»”å—',
        'æ›²é–', 'ç‰æºª', 'ä¿å±±', 'æ˜­é€š', 'ä¸½æ±Ÿ', 'æ™®æ´±', 'ä¸´æ²§', 'æ¥šé›„', 'çº¢æ²³', 'æ–‡å±±',
        'è¥¿åŒç‰ˆçº³', 'å¤§ç†', 'å¾·å®', 'æ€’æ±Ÿ', 'è¿ªåº†',
        'æ—¥å–€åˆ™', 'æ˜Œéƒ½', 'æ—èŠ', 'å±±å—', 'é‚£æ›²', 'é˜¿é‡Œ',
        'å®é¸¡', 'å’¸é˜³', 'é“œå·', 'æ¸­å—', 'å»¶å®‰', 'æ¦†æ—', 'æ±‰ä¸­', 'å®‰åº·', 'å•†æ´›',
        'æ´›é˜³', 'å¼€å°', 'å¹³é¡¶å±±', 'å®‰é˜³', 'é¹¤å£', 'æ–°ä¹¡', 'ç„¦ä½œ', 'æ¿®é˜³', 'è®¸æ˜Œ', 'æ¼¯æ²³',
        'ä¸‰é—¨å³¡', 'å—é˜³', 'å•†ä¸˜', 'ä¿¡é˜³', 'å‘¨å£', 'é©»é©¬åº—', 'æµæº',
        'æ ªæ´²', 'æ¹˜æ½­', 'è¡¡é˜³', 'é‚µé˜³', 'å²³é˜³', 'å¸¸å¾·', 'å¼ å®¶ç•Œ', 'ç›Šé˜³', 'éƒ´å·', 'æ°¸å·',
        'æ€€åŒ–', 'å¨„åº•', 'æ¹˜è¥¿',
        'èŠœæ¹–', 'èšŒåŸ ', 'æ·®å—', 'é©¬éå±±', 'æ·®åŒ—', 'é“œé™µ', 'å®‰åº†', 'é»„å±±', 'æ»å·', 'é˜œé˜³',
        'å®¿å·', 'å…­å®‰', 'äº³å·', 'æ± å·', 'å®£åŸ',
        'å”å±±', 'ç§¦çš‡å²›', 'é‚¯éƒ¸', 'é‚¢å°', 'ä¿å®š', 'å¼ å®¶å£', 'æ‰¿å¾·', 'æ²§å·', 'å»ŠåŠ', 'è¡¡æ°´',
        'å¤§åŒ', 'é˜³æ³‰', 'é•¿æ²»', 'æ™‹åŸ', 'æœ”å·', 'æ™‹ä¸­', 'è¿åŸ', 'å¿»å·', 'ä¸´æ±¾', 'å•æ¢',
        'åŒ…å¤´', 'ä¹Œæµ·', 'èµ¤å³°', 'é€šè¾½', 'é„‚å°”å¤šæ–¯', 'å‘¼ä¼¦è´å°”', 'å·´å½¦æ·–å°”', 'ä¹Œå…°å¯Ÿå¸ƒ',
        'å…´å®‰ç›Ÿ', 'é”¡æ—éƒ­å‹’ç›Ÿ', 'é˜¿æ‹‰å–„ç›Ÿ',
        'é‡‘æ˜Œ', 'ç™½é“¶', 'å¤©æ°´', 'æ­¦å¨', 'å¼ æ–', 'å¹³å‡‰', 'é…’æ³‰', 'åº†é˜³', 'å®šè¥¿', 'é™‡å—',
        'ä¸´å¤', 'ç”˜å—',
        'æµ·ä¸œ', 'æµ·åŒ—', 'é»„å—', 'æµ·å—', 'æœæ´›', 'ç‰æ ‘', 'æµ·è¥¿',
        'çŸ³å˜´å±±', 'å´å¿ ', 'å›ºåŸ', 'ä¸­å«',
        'å…‹æ‹‰ç›ä¾', 'åé²ç•ª', 'å“ˆå¯†', 'æ˜Œå‰', 'åšå°”å¡”æ‹‰', 'å·´éŸ³éƒ­æ¥', 'é˜¿å…‹è‹', 'å…‹å­œå‹’è‹',
        'å–€ä»€', 'å’Œç”°', 'ä¼ŠçŠ', 'å¡”åŸ', 'é˜¿å‹’æ³°',
        # æ¸¯æ¾³å°
        'é¦™æ¸¯', 'æ¾³é—¨', 'å°åŒ—', 'é«˜é›„', 'å°ä¸­', 'å°å—', 'æ¡ƒå›­', 'æ–°ç«¹', 'åŸºéš†', 'å˜‰ä¹‰',
        'å°ä¸œ', 'èŠ±è²', 'å®œå…°', 'è‹—æ —', 'å½°åŒ–', 'å—æŠ•', 'äº‘æ—', 'å±ä¸œ', 'æ¾æ¹–', 'é‡‘é—¨', 'é©¬ç¥–',
        # å…¶ä»–å¸¸è§åŸå¸‚
        'é„‚å·'
    }
    
    # æ¸…ç†åŸå¸‚åç§°ï¼ˆå»é™¤å¯èƒ½çš„æœºåœºåç¼€ï¼‰
    clean_city = str(city_name).replace('æœºåœº', '').replace('å›½é™…æœºåœº', '').replace('Airport', '').strip()
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºä¸­å›½åŸå¸‚
    for chinese_city in chinese_cities:
        if chinese_city in clean_city:
            return 'å›½å†…'
    
    return 'å›½å¤–'

def determine_direction(origin: str, destination: str) -> str:
    """æ ¹æ®èµ·ç‚¹å’Œç»ˆç‚¹åˆ¤æ–­è¿›å‡ºå£æ–¹å‘"""
    origin_type = categorize_city_for_direction(origin)
    dest_type = categorize_city_for_direction(destination)
    
    # å›½å†…åˆ°å›½å¤– = å‡ºå£
    if origin_type == 'å›½å†…' and dest_type == 'å›½å¤–':
        return 'å‡ºå£'
    # å›½å¤–åˆ°å›½å†… = è¿›å£
    elif origin_type == 'å›½å¤–' and dest_type == 'å›½å†…':
        return 'è¿›å£'
    # å›½å†…åˆ°å›½å†… = å›½å†…èˆªçº¿ï¼ˆæ ‡è®°ä¸ºå‡ºå£ï¼‰
    elif origin_type == 'å›½å†…' and dest_type == 'å›½å†…':
        return 'å‡ºå£'
    # å›½å¤–åˆ°å›½å¤– = å›½é™…ä¸­è½¬ï¼ˆæ ‡è®°ä¸ºå‡ºå£ï¼‰
    else:
        return 'å‡ºå£'

def extract_route_info(row: pd.Series, structure: Dict[str, Any]) -> List[Dict[str, Any]]:
    """ä»è¡Œæ•°æ®ä¸­æå–èˆªçº¿ä¿¡æ¯"""
    routes = []
    
    # ä¼˜å…ˆä½¿ç”¨æ˜ç¡®çš„èµ·ç‚¹ç»ˆç‚¹åˆ—
    if structure['origin_col'] and structure['destination_col']:
        origin = row.get(structure['origin_col'])
        destination = row.get(structure['destination_col'])
        
        if pd.notna(origin) and pd.notna(destination):
            origin_str = str(origin).strip()
            destination_str = str(destination).strip()
            direction = determine_direction(origin_str, destination_str)
            
            routes.append({
                'origin': origin_str,
                'destination': destination_str,
                'direction': direction
            })
    
    # è§£æèˆªçº¿åˆ—
    for route_col in structure['route_cols']:
        if route_col in row.index and pd.notna(row[route_col]):
            route_text = str(row[route_col]).strip()
            
            # è§£æèˆªçº¿æ–‡æœ¬
            segments = parse_route_text(route_text)
            for origin_info, dest_info in segments:
                origin_name = origin_info['name']
                dest_name = dest_info['name']
                direction = determine_direction(origin_name, dest_name)
                
                routes.append({
                    'origin': origin_name,
                    'destination': dest_name,
                    'direction': direction,
                    'origin_iata': origin_info['iata'],
                    'dest_iata': dest_info['iata']
                })
    
    return routes

def load_data(files):
    """åŠ è½½å¹¶è§£æå¤šä¸ªèˆªå¸æ•°æ®æ–‡ä»¶ - æ™ºèƒ½è§£æç‰ˆæœ¬"""
    all_rows = []
    successfully_loaded_files = []  # è®°å½•æˆåŠŸåŠ è½½çš„æ–‡ä»¶
    
    for file in files:
        try:
            print(f"æ­£åœ¨å¤„ç†æ–‡ä»¶: {os.path.basename(file)}")
            
            # å¤šç§æ–¹å¼å°è¯•è¯»å–æ–‡ä»¶
            df = None
            encodings = ['utf-8', 'gbk', 'gb2312', 'utf-8-sig']
            
            if file.lower().endswith(('.xlsx', '.xls')):
                try:
                    df = pd.read_excel(file, engine='openpyxl')
                except:
                    try:
                        df = pd.read_excel(file, engine='xlrd')
                    except:
                        print(f"æ— æ³•è¯»å–Excelæ–‡ä»¶: {file}")
                        continue
            elif file.lower().endswith('.csv'):
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file, encoding=encoding)
                        break
                    except:
                        continue
                if df is None:
                    print(f"âš ï¸ è·³è¿‡æ— æ³•è¯»å–çš„CSVæ–‡ä»¶: {os.path.basename(file)}")
                    continue
            else:
                # å°è¯•è‡ªåŠ¨æ£€æµ‹æ ¼å¼
                for encoding in encodings:
                    try:
                        df = pd.read_csv(file, encoding=encoding)
                        break
                    except:
                        try:
                            df = pd.read_excel(file)
                            break
                        except:
                            continue
                if df is None:
                    print(f"âš ï¸ è·³è¿‡æ— æ³•è¯†åˆ«æ ¼å¼çš„æ–‡ä»¶: {os.path.basename(file)}")
                    continue
            
            if df is None or df.empty:
                print(f"âš ï¸ è·³è¿‡ç©ºæ–‡ä»¶: {os.path.basename(file)}")
                continue
            
            print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {df.shape}")
            print(f"åˆ—å: {list(df.columns)}")
            
            # æ™ºèƒ½æ£€æµ‹è¡¨æ ¼ç»“æ„
            structure = detect_table_structure(df)
            print(f"æ£€æµ‹åˆ°çš„ç»“æ„: {structure}")
            
            # æ¸…ç†å’Œæ ‡å‡†åŒ–æ•°æ®
            df_clean = clean_and_normalize_data(df, structure)
            print(f"æ¸…ç†åæ•°æ®å½¢çŠ¶: {df_clean.shape}")
            
            # ä»æ–‡ä»¶åæå–èˆªå¸åç§°
            airline_name = os.path.basename(file).split('.')[0]
            # æ¸…ç†æ–‡ä»¶åä¸­çš„å‰ç¼€
            for prefix in ['ç¤ºä¾‹æ•°æ®_', 'æ•°æ®_', 'sample_', 'data_']:
                if airline_name.startswith(prefix):
                    airline_name = airline_name[len(prefix):]
                    break
            
            # å¤„ç†æ¯ä¸€è¡Œæ•°æ®
            processed_count = 0
            for idx, row in df_clean.iterrows():
                # è·å–èˆªå¸åç§°
                airline_value = None
                if structure['airline_col'] and structure['airline_col'] in row.index:
                    airline_value = row[structure['airline_col']]
                
                # å¦‚æœæ²¡æœ‰èˆªå¸åˆ—æˆ–èˆªå¸ä¸ºç©ºï¼Œä½¿ç”¨æ–‡ä»¶å
                if pd.isna(airline_value) or str(airline_value).strip() == '':
                    airline_value = airline_name
                
                if pd.isna(airline_value) or str(airline_value).strip() == '':
                    continue  # è·³è¿‡æ— æ³•ç¡®å®šèˆªå¸çš„è¡Œ
                
                # æå–èˆªçº¿ä¿¡æ¯
                routes = extract_route_info(row, structure)
                
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°èˆªçº¿ä¿¡æ¯ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
                if not routes:
                    # æ£€æŸ¥æ˜¯å¦æœ‰æœªè¯†åˆ«çš„åˆ—åŒ…å«èˆªçº¿ä¿¡æ¯
                    for col in df_clean.columns:
                        if col not in [structure.get(k) for k in structure.keys() if k.endswith('_col')]:
                            col_value = row[col]
                            if pd.notna(col_value) and '-' in str(col_value):
                                segments = parse_route_text(str(col_value))
                                for origin_info, dest_info in segments:
                                    routes.append({
                                        'origin': origin_info['name'],
                                        'destination': dest_info['name'],
                                        'direction': 'å‡ºå£',
                                        'origin_iata': origin_info['iata'],
                                        'dest_iata': dest_info['iata']
                                    })
                                break
                
                # ä¸ºæ¯ä¸ªèˆªçº¿åˆ›å»ºè®°å½•
                for route_info in routes:
                    # è·å–å…¶ä»–å­—æ®µå€¼
                    reg_value = ''
                    if structure['reg_col'] and structure['reg_col'] in row.index:
                        reg_value = row[structure['reg_col']] if pd.notna(row[structure['reg_col']]) else ''
                    
                    aircraft_value = ''
                    if structure['aircraft_col'] and structure['aircraft_col'] in row.index:
                        aircraft_value = row[structure['aircraft_col']] if pd.notna(row[structure['aircraft_col']]) else ''
                    
                    age_value = ''
                    if structure['age_col'] and structure['age_col'] in row.index:
                        age_value = row[structure['age_col']] if pd.notna(row[structure['age_col']]) else ''
                    
                    flight_number_value = ''
                    if structure['flight_number_col'] and structure['flight_number_col'] in row.index:
                        flight_number_value = row[structure['flight_number_col']] if pd.notna(row[structure['flight_number_col']]) else ''
                    
                    frequency_value = 'æ­£å¸¸è¿è¥'
                    if structure['frequency_col'] and structure['frequency_col'] in row.index:
                        frequency_value = row[structure['frequency_col']] if pd.notna(row[structure['frequency_col']]) else 'æ­£å¸¸è¿è¥'
                    
                    special_value = ''
                    if structure['special_col'] and structure['special_col'] in row.index:
                        special_value = row[structure['special_col']] if pd.notna(row[structure['special_col']]) else ''
                    
                    # è·å–é£è¡Œæ—¶é—´å’Œè·ç¦»
                    flight_time_value = ''
                    flight_distance_value = ''
                    
                    for time_col in structure['flight_time_cols']:
                        if time_col in row.index and pd.notna(row[time_col]):
                            flight_time_value = str(row[time_col])
                            break
                    
                    for dist_col in structure['flight_distance_cols']:
                        if dist_col in row.index and pd.notna(row[dist_col]):
                            flight_distance_value = str(row[dist_col])
                            break
                    
                    all_rows.append({
                        "direction": route_info.get('direction', 'å‡ºå£'),
                        "airline": str(airline_value).strip(),
                        "reg": str(reg_value).strip(),
                        "aircraft": str(aircraft_value).strip(),
                        "age": str(age_value).strip(),
                        "origin": route_info['origin'],
                        "origin_iata": route_info.get('origin_iata', ''),
                        "destination": route_info['destination'],
                        "dest_iata": route_info.get('dest_iata', ''),
                        "flight_time": str(flight_time_value).strip(),
                        "flight_distance": str(flight_distance_value).strip(),
                        "special": str(special_value or frequency_value).strip(),
                        "flight_number": str(flight_number_value).strip()
                    })
                    processed_count += 1
            
            print(f"ä»æ–‡ä»¶ {os.path.basename(file)} ä¸­æå–äº† {processed_count} æ¡èˆªçº¿è®°å½•")
            successfully_loaded_files.append(os.path.basename(file))  # è®°å½•æˆåŠŸåŠ è½½çš„æ–‡ä»¶
            
        except Exception as e:
            print(f"å¤„ç†æ–‡ä»¶ {file} æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
            continue
    
    result_df = pd.DataFrame(all_rows)
    
    # æ•°æ®åˆå¹¶ç»Ÿè®¡
    if len(successfully_loaded_files) > 1:
        print(f"\nğŸ“Š æ•°æ®åˆå¹¶ç»Ÿè®¡ï¼š")
        print(f"   æˆåŠŸåŠ è½½æ–‡ä»¶æ•°é‡ï¼š{len(successfully_loaded_files)}")
        print(f"   åˆå¹¶åæ€»è®°å½•æ•°ï¼š{len(result_df)}")
        
        # æŒ‰èˆªå¸ç»Ÿè®¡
        if 'airline' in result_df.columns:
            airline_counts = result_df['airline'].value_counts()
            print(f"   æ¶‰åŠèˆªå¸æ•°é‡ï¼š{len(airline_counts)}")
            for airline, count in airline_counts.head(5).items():
                print(f"     - {airline}: {count} æ¡è®°å½•")
            if len(airline_counts) > 5:
                print(f"     - å…¶ä»– {len(airline_counts) - 5} ä¸ªèˆªå¸...")
    else:
        print(f"æ€»å…±åŠ è½½äº† {len(result_df)} æ¡èˆªçº¿è®°å½•")
    
    # å°†æˆåŠŸåŠ è½½çš„æ–‡ä»¶ä¿¡æ¯æ·»åŠ åˆ°DataFrameçš„å…ƒæ•°æ®ä¸­
    result_df.attrs['successfully_loaded_files'] = successfully_loaded_files
    return result_df